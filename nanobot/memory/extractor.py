"""Fact extraction from conversations."""

from typing import Any

from loguru import logger

from nanobot.providers.base import LLMProvider

# Extraction prompt template
EXTRACTION_PROMPT = """Analyze this conversation and extract key facts that should be remembered long-term.

Focus on:
1. **User preferences** - Things the user likes/dislikes, habits, preferences
2. **Important decisions** - Choices made, approaches agreed upon
3. **Personal details** - Names, dates, relationships mentioned
4. **Commitments** - Tasks promised, deadlines set
5. **Technical details** - Project specifics, configurations, requirements

Conversation:
{conversation}

Output each fact on a separate line. Be concise but specific.
Only include facts worth remembering across conversations.
If there are no significant facts, output "NO_FACTS".

Facts:"""


class FactExtractor:
    """
    Extracts key facts from conversations for long-term memory.

    Uses an LLM to identify important information worth indexing
    separately from raw conversation turns.
    """

    def __init__(
        self,
        provider: LLMProvider,
        model: str | None = None,
    ):
        """
        Initialize the extractor.

        Args:
            provider: LLM provider for extraction.
            model: Model to use (None = provider default).
        """
        self.provider = provider
        self.model = model

    async def extract_facts(
        self,
        messages: list[dict[str, Any]],
    ) -> list[str]:
        """
        Extract key facts from a conversation.

        Args:
            messages: Conversation messages to analyze.

        Returns:
            List of extracted facts.
        """
        if not messages:
            return []

        # Format conversation for the prompt
        formatted = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            if content and role in ("user", "assistant"):
                formatted.append(f"{role.upper()}: {content}")

        if not formatted:
            return []

        conversation_text = "\n\n".join(formatted)
        prompt = EXTRACTION_PROMPT.format(conversation=conversation_text)

        try:
            response = await self.provider.chat(
                messages=[{"role": "user", "content": prompt}],
                model=self.model,
                max_tokens=512,
                temperature=0.3,
            )

            content = response.content or ""

            if "NO_FACTS" in content.upper():
                return []

            # Parse facts from response
            facts = []
            for line in content.strip().split("\n"):
                line = line.strip()
                # Skip empty lines and headers
                if line and not line.startswith("#") and len(line) > 10:
                    # Remove common prefixes
                    if line.startswith("- "):
                        line = line[2:]
                    elif line[0].isdigit() and line[1] in ".)" and line[2] == " ":
                        line = line[3:]
                    facts.append(line)

            logger.debug(f"Extracted {len(facts)} facts from conversation")
            return facts

        except Exception as e:
            logger.error(f"Fact extraction failed: {e}")
            return []

    async def extract_from_turn(
        self,
        user_message: str,
        assistant_message: str,
    ) -> list[str]:
        """
        Extract facts from a single conversation turn.

        Args:
            user_message: The user's message.
            assistant_message: The assistant's response.

        Returns:
            List of extracted facts.
        """
        messages = [
            {"role": "user", "content": user_message},
            {"role": "assistant", "content": assistant_message},
        ]
        return await self.extract_facts(messages)
